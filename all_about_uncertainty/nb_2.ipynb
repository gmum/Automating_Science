{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this a half hour coding session is to make a simple observation that can be noticed when rotating the digit 1 (MNIST) and its effect on the uncertainty. Ref: https://arxiv.org/pdf/1806.01768.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to substitute this idea by something more challenging / different application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rotating](rotating_page-0001.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rotating.pdf](cls_probs__page-0001.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rotating.pdf](rotating_dir_page-0001.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rotating.pdf](cls_probs_dir_page-0001.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.ndimage as nd\n",
    "import scipy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import mnist\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: load mnist (normalized [0,1], with one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1b. Plot one of the image from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1c. Split into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Define your Lenet-5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Define training objective (CE / MSE) and way to compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Initialize your model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Write train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5b. Execute it and plot train/test loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Take benefit of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "mnist_size = 28\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def rotate_img(x, deg):\n",
    "    return nd.rotate(x.reshape(mnist_size,mnist_size),deg,reshape=False).ravel()\n",
    "\n",
    "\n",
    "def rotating_image_classification(img, model, uncertainty=None, threshold=0.5):\n",
    "    Mdeg = 180 \n",
    "    Ndeg = int(Mdeg/10)+1\n",
    "    ldeg = []\n",
    "    lp = []\n",
    "    lu=[]\n",
    "    scores = np.zeros((1,n_classes))\n",
    "    rimgs = np.zeros((mnist_size,mnist_size*Ndeg))\n",
    "    for i,deg in enumerate(np.linspace(0,Mdeg, Ndeg)):\n",
    "        nimg = rotate_img(img,deg).reshape(mnist_size,mnist_size)\n",
    "        nimg = np.clip(a=nimg,a_min=0,a_max=1)\n",
    "        rimgs[:,i*mnist_size:(i+1)*mnist_size] = nimg\n",
    "        single_input = torch.reshape(torch.tensor(nimg), (1, 1, mnist_size, mnist_size))\n",
    "        p_pred_t = softmax(model(single_input)).detach().numpy()\n",
    "        scores += (p_pred_t >= threshold)\n",
    "        ldeg.append(deg) \n",
    "        lp.append(p_pred_t[0])\n",
    "        if uncertainty is not None:\n",
    "            # TODO:\n",
    "            u = None\n",
    "            lu.append(u)\n",
    "        scores += p_pred_t >= threshold\n",
    "\n",
    "    labels = np.arange(10)[scores[0].astype(bool)]\n",
    "    lp = np.array(lp)[:,labels]\n",
    "    c = ['black','blue','red','brown','purple','cyan']\n",
    "    marker = ['s','^','o']*2\n",
    "    labels = labels.tolist()\n",
    "    for i in range(len(labels)):\n",
    "        plt.plot(ldeg,lp[:,i],marker=marker[i],c=c[i])\n",
    "\n",
    "    if uncertainty is not None:\n",
    "        labels += ['uncertainty']\n",
    "        plt.plot(ldeg,lu,marker='<',c='red')\n",
    "        \n",
    "    plt.legend(labels)\n",
    "\n",
    "    plt.xlim([0,Mdeg])\n",
    "    plt.xlabel('Rotation Degree')\n",
    "    plt.ylabel('Classification Probability')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=[6.2,100])\n",
    "    plt.imshow(1-rimgs,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7. Expected Mean-Squared Error (get familiarized with the paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in the paper, a neural network can be trained to learn parameters of a Dirichlet distribution, instead of softmax probabilities. Dirichlet distributions with parameters $\\alpha \\geq 1$ behaves like a generative model for softmax probabilities (categorical distributions). It associates a likelihood value with each categorical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8. Off you go! you know what to do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "as",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
